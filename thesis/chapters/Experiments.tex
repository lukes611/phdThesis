\makeatletter
\chapter{Experiments}
\label{ch:Experiments}

\section{Experiments}
\input{chapters/Experiments/Experiments/Intro}

\section{Tools}
\label{ToolsSection}
\input{chapters/Experiments/Experiments/Tools}

\section{Error metrics}
\label{metricsSection}
\input{chapters/Experiments/Experiments/Metrics}

%sota results
\section{Data Sources}
\label{Sec:FVRSOTA}
\subsection{Algorithms} 
\label{AlgorithmsSection}
\input{chapters/Experiments/FVR/Algorithms}

\subsection{Sensor Types} 
\label{SensorTypesExpsSection}
\input{chapters/Experiments/FVR/CameraMethods}

%stereo tests
\subsection{Stereo Camera}
\label{StereoSOTA}
\input{chapters/Experiments/FVR/Stereo}

%active camera-tests
\subsection{Active Camera}
\label{ActiveSOTA}
\input{chapters/Experiments/FVR/Active}

%monocular-tests
\subsection{Monocular Camera}
\label{Sec:MonocularSOTA}
\input{chapters/Experiments/FVR/Monocular}

%the basic tracking stuff
\section{Camera Tracking \& Noise Robustness}
\label{Sec:CamTransTrackExp}
\input{chapters/Experiments/FVR/BasicTracking}

\subsection{Comparison}

Here we present a summary table (Table \ref{tab:GridRT}) to assess the various abilities of each 3D reconstruction algorithm in terms of translation, rotation, scale, non-static object motion robustness and ability to handle various sensory types. In terms of translation, each of the presented algorithms can register with respect to translation. In experiments, it was shown that the FVR algorithm outperforms others when this type of camera movement is present, especially at wider baselines of 10 to 15 cm. In registering rotation, the FVR and FFVR methods are only capable of a single axis of rotation. FVR-3D, however, can register against all 3 axes of rotation. Results have shown that in the presence of rotation, the FVR-3D performs at or above the level of the more accurate algorithms from the literature, ICP and FM2D. It was found that MVVR was not able to handle rotation well, due to the high levels of noise found in the depth maps produced by monocular based techniques. \\

Only the FVR and FVR-3D methods were capable of registering against scale. From the literature, ICP and PCA are not capable of handling such transformations without some modification. Results have shown that these algorithms are capable of handling non-static object motion well. Results on the Kitti Vision benchmark show that FVR-3D outperforms the state-of-the-art, even on data sets which have non-static moving agents. Results also showed that the FVR was the most accurate in the registration of wide baselines, that is translations above 5 cm and rotations above 5 degrees. The FVR algorithm outperformed the others, including the top methods used in the literature. Of these methods, MVVR was shown to be able to register monocular sensor data against translation when noise levels were low. The closer the depth data computed via monocular methods approaches perfectly accurate depth images, the closer the MVVR algorithm approaches FVR performance. In terms of both stereo and active sensor input, FVR, FFVR and FVR-3D are all capable of handling this type of input data well. \\


\begin{table}[h]
\centering
\caption{FVR Comparison Table \label{tab:GridRT}}
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccccccccc}
\textbf{\textit{Algorithm}} & \textbf{translation} & \textbf{rotation} & \textbf{scale} & \textbf{object motion} & \textbf{wide baselines} & \textbf{monocular} & \textbf{stereo} & \textbf{RGB-D}\\ \hline
FVR & yes & 1 axis only & yes & yes & yes & no & yes & yes\\
FFVR & yes & 1 axis only & no & yes & no & no & yes & yes\\
FVR-3D & yes & yes & yes & yes & no & no & yes & yes\\
MMVR & yes & no & no & no & no & yes & no & no\\
\end{tabular}}
\label{tab:ExperimentsBooleanSummary}
\end{table}


In summary, the stereo camera and active camera results, show that FVR-3D method outperforms all the other algorithms from the literature. For most of these data sets the FVR algorithm was a strong second place contender. When registering wider baselines, the FVR algorithm was the top performer while FVR-3D fell behind.

%PTPTPT
\section{Plane-Tree Experiments}
\input{chapters/Experiments/PT/Intro}
\section{Plane-Tree vs. Octree}
\label{SEC:PTVSOT}
\input{chapters/Experiments/PT/OT}
\section{Plane-Tree vs. Existing Techniques}
\label{SEC:PTVSSOTA}
\input{chapters/Experiments/PT/SOTA}
\section{Plane-Tree: Qualitative Results}
\label{SEC:PTQUALEVAL}
\input{chapters/Experiments/PT/Qualitative}
\section{Plane-Tree: Reconstruction Compression}
\label{SEC:PTONRECON}
\input{chapters/Experiments/PT/Recon}



