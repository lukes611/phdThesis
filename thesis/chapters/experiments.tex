\begin{savequote}[8cm]
  ``I just wondered how things were put together.''
  \qauthor{Claude Shannon}
\end{savequote}
\makeatletter
\chapter{Experiments}

\section{Experiments}

In this section, various experiment set-ups and test data are discussed. Results are presented in the results section (\ref{ResultsSection}). In this section we first discuss the test data used in section \ref{TestDataSection}, then the tools we used for analysis are discussed (section \ref{ToolsSection}). The algorithms we evaluated and compared are listed in section \ref{AlgorithmsSection}. Finally in the later sections (\ref{QualExperimentsSection} and beyond) we discuss the quantitative and qualitative methods we used to test these algorithms. Finally section \ref{DataRepresentationExperimentsSection} describes the experiments evaluating the proposed Reconstruction data-representation. 

\section{Test Data}

\label{TestDataSection}

Test Data was generated based on the testing requirements for this research. In order to robustly test different pose-estimation procedures / 3D-registration methods we generated data from a variety of scenes. These scenes are of both in-door and out-door. Some include large amounts of texture whilst others have little or no texture. Some scenes in the data-set were captured purposefully to cause confusion for algorithms which rely on texture information. These scenes have texture confusion. These scenes have multiple items which look similar locally but are actually different objects within the scene and have unique global positions. \\

Moreover, our test-data also measures the ability of each algorithm to register different camera movements. Each scene is captured by performing certain types of camera movement. Different camera transformations captured include: translation, zooming and rotation about different axes. \\

Some frames from the original test-set are shown in appendix \ref{AppendixA}. The first scene: the Apartment Texture Rotate scene was taken by rotating the camera around the y-axis across an apartment. This scene contains a lot of texture information. The Apartment Texture X Axis scene is similar in terms of texture but contains both x and y axis rotation. This tests the FVR's ability to handle multiple axes of rotation. \\

The boxes scene was captured under arbitrary-rotation, translation and zoom (in/out) camera motions. It contains some useful information on the boxes themselves, however the texture on the carpet is may cause texture confusion for feature based registration methods. The Desk Texture Translation scene contains a desk with a desktop computer and several items on it. The In-door space with texture-confusion contains a set of chairs and picture frames which look similar to each-other locally but may cause confusion for registration techniques which rely on local features.  \\

The kitchen scene was captured with both translation and zoom camera movements. It contains very little texture and the color is predominantly white. The Office textured blind-spot rotation scene is a textured office scene where the camera is rotated about the y-axis. The scene is focused on a large divider which separates two desks. The divider may confuse registration methods which rely too heavily on minimization by aligning the large divider as a priority rather than taking into account the smaller details within the scene. \\

The Office scenes contain a decent amount of usable texture and different sets were created by translating, rotating about the y-axis and rotating about the x-axis. Other office scenes, where the camera captures objects in both the foreground and the background and where the camera is lifted and rotated whilst focussed on an office desk and chair combo. \\

Some out-door scenes were also captured around the university. They are captured with both rotation and translation camera movements and are also labelled as being susceptible to texture confusion.

\section{Analysis Tools}
\label{ToolsSection}

In order to test different registration methods. Algorithms were written in C/C++ using both Visual Studio (2012 and 2015) on a Windows (7 \& 10) machine and code-blocks 16 on an Ubuntu machine. All source code is made available online at: https://github.com/lukes611/phdThesis. In order to measure registration algorithms we use the error metrics described in the \ref{metricsSection} section.  

\section{Algorithms}
\label{AlgorithmsSection}

\subsection{3D Reconstruction}

Different 3D-registration algorithms were implemented to test the Fourier Volume Registration (FVR) method. Feature matching methods are important to compare with because they are still dominant and very successful in image processing and computer vision. In this research we show that FVR is competitive with feature matching methods whilst beating them in certain contexts (such as little textured scenes or scenes where texture confusion may occur). \\ 

We test with both 2D feature matching and 3D feature matching. In 2D feature matching, the features are found and matched between a pair of 2D-images, then RANSAC is used with the corresponding matches and true 3D point to compute pose. The pose is then used to reconstruct the scene. We found that SURF performed best out of the other feature matching methods, so SURF was used in experiments. The 2D feature matching method is limited as it cannot register frames which have too few features or frames which contain texture confusion. It is also not able to handle wide base-lines. \\

We also test 3D-feature matching using an implementation of SIFT in 3D. This algorithm was tested and written in C/C++ and like the 2D counterpart, is also susceptible to failed registration in scenes with too few features and texture confusion but it is able to handle wide base-lines since it works in 3D. //

Another algorithm used in experiments is Iterative Closest Point or ICP. This method has become very popular in 3D reconstruction and works well on most scene types. One disadvantage is that this method may get stuck in a local minima and fail to register correctly. This typically occurs when registering against wide-baselines. \\

Another algorithm present in the experiments is Principal Components Analysis (PCA). This algorithm is used to find the mean and principal components of a multi-dimensional data set. This is useful for registration purposes as it works on wide-baselines, is very fast and provides additional information about a scene. The downside is that it is very susceptible to noise and misaligned data. The proposed FVR method makes use of information from PCA so it is important to compare the two to find out what improvements are made by FVR over PCA. \\

The final algorithm tested is the proposed FVR algorithm, which uses both PCA and Fourier Phase Correlation to find the registration transformation between two 3D data-sets as described in \ref{FullRecovery3DSection}. This algorithm was proposed to handle general transformations in terms of rotation, scaling and translation. It was also designed to be able to handle noisy data, data with texture-confusion and data with little or no texture. This makes it a viable option in the 3D registration and pose estimation research areas.

\section{Qualitative Experiments}

\label{QualExperimentsSection}

Qualitative experiments were performed by using different algorithms to generate 3D reconstructed scenes. The scenes include some indoor and out-door scenes. They are analysed visually in the results section. 

\section{Quantitative Experiments}

\subsection{Pose Estimation Experiments}

Quantitative experiments were performed by registering multiple frames from the different scenes mentioned in the algorithms section. We use the test-data mentioned, and estimate pose for each frame. Results from a few metrics were gathered, including: Mean Squared Error, Percent Match and Hausdorff Error. We found that measuring the Hausdorff error relative to the Hausdorff error between the two un-registered frames provided the most clear indication of performance and accuracy. We provide results for each of the raw measurements in the Appendix \ref{RawQuantitative1}.


\subsection{Camera Movement Experiments}

Experiments are performed where by the camera is translated or rotated and the registration transform is compared to the true camera movement and the error between the true and computed camera movement is presented. These experiments were performed to show the FVR's ability to register accurate camera movements in the presence of noise.

\subsection{Noise Experiments}

Experiments determining each algorithm's robustness to noise are performed similarly to pose estimation experiments in that specific transforms are applied to real data. Each algorithm's ability to register against such transforms is evaluated. However, in these tests we apply different amounts of noise to data and compare each registration to that of the registration of data minus the noise. Raw results are provided in Appendix \ref{RaqQualitative2}


\section{Data Representation Experiments}

Data representation experiments compare the compression of the Octree with the proposed data representation method. The mean squared error is used and graphs showing bit-rate vs error are shown comparing both methods.
