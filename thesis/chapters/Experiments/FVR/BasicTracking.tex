\section{Camera Translation Tracking}
\label{Sec:CamTransTrackExp}

Experiments measuring the error after moving the camera using the FVR based methods as well as other methods from the literature are presented in this section. For these experiments, one camera frame of an indoor environment was captured using the ASUS Xtion PRO LIVE active camera. The camera was then moved (translated) by different amounts including: 5 centimeters, 10 centimeters and 15 centimeters. The 2D and 3D Feature matching / Ransac methods (FM2D, FM3D), ICP and PCA methods were all tested. Additionally, results for the FVR, FFVR and FVR3D method are presented. FM3D, FVR and FVR3D require the 3D frames be quantized into $256\times 256\times 256$ volumes. \\

Different levels of noise were added to both frames prior to 3D registration in order to measure each method's ability to register frames with large amounts of noise. The Signal to Noise Ratio (SNR) metric is used to describe the noise added to both captured frames, prior to any registration. This noise effects any registration method's ability to accurately estimate the transformation separating two sets of data. In a given experiment, a noise range value of $x$ means random noise was added in the range [$\frac{-x}{2}$, $\frac{x}{2}$] to a signal within the range [0, 1]. Reconstruction error is measured in mean squared error (as presented in section \ref{metricsSection}). \\

Table \ref{table:trans} shows the results of these tests, they illustrate the FVR's robustness to noise whilst registering frames which are captured during different camera translation intervals. Each sub-table is labelled with a distance in centimeters in which frames were separated prior to registration. The first two columns represent the amount of noise added both in terms of noise-range and the subsequent Signal to Noise ratio computed from it. The rest of the columns represent the registration error using the Mean Squared Error metric.  \\

%translation
\begin{table}[!htb]
\centering
\scalebox{1.0}{
\begin{tabular}{ccccccccc}
\\ \textbf{5cm} &   &   &   &   &   &   &   &   \\ 
Noise & SNR & \textbf{FM2D} & \textbf{FM3D} & \textbf{ICP} & \textbf{PCA} & \textbf{FVR} & \textbf{FFVR} & \textbf{FVR3D} \\ \hline
0 & $\infty$ & 5.07 & 4.75 & 12.35 & 3.73 & 4.04 & fail & 6.24 \\
0.1 & 20db & 18.96 & fail & fail & 2.33 & 2.73 & 14.6 & 5.63 \\
0.25 & 12db & 5.12 & 4.3 & 2.03 & 4.2 & 4.13 & 5.51 & 2.3 \\
0.5 & 6db & 5.61 & 1.95 & 3.71 & 6.83 & 3.7 & 7.73 & 2.83 \\
0.75 & 2.5db & 5.02 & 8.57 & 6.41 & 20.94 & 2.24 & 6.5 & 4.33 \\
\\ \textbf{10cm} &   &   &   &   &   &   &   &   \\ 
Noise & SNR & \textbf{FM2D} & \textbf{FM3D} & \textbf{ICP} & \textbf{PCA} & \textbf{FVR} & \textbf{FFVR} & \textbf{FVR3D} \\ \hline
0 & $\infty$ & 15.35 & fail & 10.26 & 16.87 & 3.47 & fail & 7.07 \\
0.1 & 20db & 18.2 & 15.36 & 6.24 & fail & 3.89 & fail & 11.45 \\
0.25 & 12db & fail & 24.12 & 6.02 & 20.12 & 5.4 & fail & 7.53 \\
0.5 & 6db & fail & 4.42 & 5 & 3.96 & 4.65 & fail & 9.47 \\
0.7 & 2.5db & 7.27 & 8.57 & 3.98 & 7.85 & 15.45 & fail & 4.3 \\
\\ \textbf{15cm} &   &   &   &   &   &   &   &   \\ 
Noise & SNR & \textbf{FM2D} & \textbf{FM3D} & \textbf{ICP} & \textbf{PCA} & \textbf{FVR} & \textbf{FFVR} & \textbf{FVR3D} \\ \hline
0 & $\infty$ & fail & fail & 7.85 & fail & 25.87 & fail & fail \\
0.1 & 20db & fail & fail & 7.13 & fail & 12.27 & fail & fail \\
0.25 & 12db & 15.17 & fail & fail & fail & 8.1 & 12.52 & fail \\
0.5 & 6db & fail & fail & 11.11 & fail & 10.13 & 11.09 & fail \\
0.7 & 2.5db & fail & fail & 10.31 & 20.59 & 7.79 & fail & fail \\
\\
\end{tabular}}
\\
\caption{Translation Tracking}
\label{table:trans}
\end{table}


Results show that the basic FVR method is generally the most accurate in terms of registration across the range of camera translation magnitudes and noise levels. In comparison, the FFVR method reduces processing time at the expense of accuracy, results show that in general it is only capable of up to 5cm of translation registration. FVR3D and the 2D feature matching method are capable of registering 5-10cm with larger levels of noise. However, both methods fail to register the full 15cm of camera translation well. \\

ICP performed next best, capable of performing well up to 15cm of translation, but failing to register twice during the tests. PCA was able to handle up to 10cm of too but often had larger registration errors. For the 15cm translation tests, the FVR performed the best followed by ICP, which failed once but outperformed FVR within the two lowest noise brackets. \\


It can be shown that, despite being limited to a single axis of rotation, the FVR algorithm can consistently register camera movements up to 15cm better than other algorithms from the literature. To put these camera translations into perspective at video frame rates, a displacement of 10cm per frame equates to camera velocity of 3 meters per second, this is twice the average person's walking speed making both the FVR method and FVR3D suitable for a majority of applications. \\


\section{Camera Rotation Tracking}
\label{Sec:CamRoteTrackExp}

Table \ref{table:rote} shows results for camera rotation experiments. These experiments were captured with the ASUS Xtion PRO LIVE camera using the same scene as results in section \ref{Sec:CamTransTrackExp}. 3D frames of these scenes are separated by 10, 20 and 30 degrees of camera rotation about the y-axis. These degrees were chosen because they are significantly large enough to be difficult for these algorithms to register against.  \\

Again, different levels of noise were added to each frame prior to registration. This experiment was designed to test the robustness of the FVR based methods in registering camera pose. \\


%rotation
\begin{table}[!htb]
\centering
\scalebox{1.0}{
\begin{tabular}{ccccccccc}
\\ \textbf{10deg} &   &   &   &   &   &   &   &   \\ 
Noise & SNR & \textbf{FM2D} & \textbf{FM3D} & \textbf{ICP} & \textbf{PCA} & \textbf{FVR} & \textbf{FFVR} & \textbf{FVR3D} \\ \hline
0 & $\infty$ & 0.17 & 9.77 & 0.19 & 0.3 & 0.18 & 0.35 & 4.05 \\
0.1 & 20db & 0.21 & 0.41 & 0.17 & 0.67 & 0.15 & 0.21 & 10.54 \\
0.25 & 12 & 0.16 & 0.34 & 0.13 & 0.39 & 0.15 & 0.44 & 5.44 \\
\\ \textbf{20deg} &   &   &   &   &   &   &   &   \\ 
Noise & SNR & \textbf{FM2D} & \textbf{FM3D} & \textbf{ICP} & \textbf{PCA} & \textbf{FVR} & \textbf{FFVR} & \textbf{FVR3D} \\ \hline
0 & $\infty$ & 1.37 & 13.1 & 1.81 & 16.93 & 7.29 & 1.32 & 3.18 \\
0.1 & 20db & 1.35 & 14.32 & 15.29 & 2.97 & 0.7 & 2.03 & 1.92 \\
0.25 & 12db & 1.6 & 3.26 & 14.7 & 0.64 & 1.54 & 4.29 & 2.24 \\
\\ \textbf{30deg} &   &   &   &   &   &   &   &   \\ 
Noise & SNR & \textbf{FM2D} & \textbf{FM3D} & \textbf{ICP} & \textbf{PCA} & \textbf{FVR} & \textbf{FFVR} & \textbf{FVR3D} \\ \hline
0 & $\infty$ & 3.87 & 10.15 & 3.16 & 9.97 & 2.11 & 5.68 & 3.63 \\
0.1 & 20db & 3.77 & 16.65 & 39.37 & 77.6 & 3.84 & 2.82 & 1.39 \\
0.25 & 12db & 3.68 & 2.76 & 5.12 & 5.78 & 3.3 & 7.15 & 6.38 \\
\\
\end{tabular}}
\\
\caption{Rotation Tracking}
\label{table:rote}
\end{table}

In the first sub-table, registration errors for 10 degrees of rotation are presented. Results show that the FVR method outperforms the other methods. Here, ICP performs next best followed by the 2D feature matching method. This was expected as the FVR method was designed to be both robust to noise and to handle larger rotations. It can also be seen that in the 20 degree and 30 degree tests, the FVR method also beats both of these algorithms in terms of having to lower registration error. FFVR also worked well at different noise levels up to 30 degrees of rotation. FVR3D was found to be as robust as ICP at registering rotation but not at accurate as the 2D feature matching method. \\ 

It should be noted that twelve degrees of camera rotation per frame is almost a full rotation per second in video rates. This is so fast that most cameras would acquire too much motion blur for registration to be possible. Therefore this test indicates the robustness of the FVR method in comparison with the other algorithms within the context of camera pose estimation. \\


\section{Reconstructed Scenes}
\label{Sec:FVRQual1Exp}

\begin{figure}[!htb] 
        \centering
        \begin{subfigure}[b]{3.0in}
                \includegraphics[width=3.0in]{images/ch2/unit21}
                \caption{Apartment}
                \label{fig:RECON_UNIT}
        \end{subfigure}
        \begin{subfigure}[b]{3.0in}
                \includegraphics[width=3.0in]{images/ch2/officeA}
                \caption{Office}
                \label{fig:RECON_OFFICE}
        \end{subfigure}
        \begin{subfigure}[b]{3.0in}
                \includegraphics[width=3.0in]{images/ch2/outdoorA}
                \caption{Garden}
                \label{fig:RECON_GARDEN}
        \end{subfigure}
       \caption{Reconstructed Scenes.}
       \label{fig:RECONSTRUCTIONS}
\end{figure}

Qualitative experiments also show the ability of the FVR registration method to reconstruct 3D scenes. In these experiments, two indoor environments (Apartment and Office) as well as one outdoor environment (Garden) were reconstructed and are shown in figures \ref{fig:RECON_UNIT}, \ref{fig:RECON_OFFICE} and \ref{fig:RECON_GARDEN} respectively. \\

The Apartment reconstruction was recorded by moving the ASUS Xtion PRO LIVE active camera through a room and rotating the camera. Each frame was registered using the FVR algorithm. Some of the frames in the apartment scene contain walls which have few features. Between frames, walls also had colour contrast shifts. These shifts are due to the ASUS camera's automatic contrast feature which adjusts contrast based on colour histograms. Despite these setbacks, accurate 3D reconstruction was achieved by the FVR method as illustrated in figure \ref{fig:RECON_UNIT}. \\


The office reconstruction was also generated by rotating the ASUS Xtion PRO LIVE active camera about the y-axis while moving the camera around the room. This time, during rotation, the camera was focused on both foreground and background objects. Here, the entire video sequence was accurately registered. It can be seen that despite the foreground and background focus, the global reconstruction is accurate. This scene, as in the apartment scene has usable texture which should not cause large amounts of texture confusion. These qualitative experiments show that despite being a closed form solution, the FVR has reconstruction accuracy comparable to existing feature based SLAM methods. \\


Typical feature based methods work well with indoor environments where local features are readily distinguishable and easy to match. They do not tend to work as well in complex outdoor scenes where feature confusion is likely. To assess performance in such outdoor scenes, a garden scene containing bushes, plants and a ground covering of bark and rocks was captured for testing. Again, this scene was captured using the ASUS Xtion PRO LIVE active camera moving around the out-door garden. The proposed FVR method was able to produce a good quality reconstruction of this garden scene, as shown in figure \ref{fig:RECON_GARDEN}. This shows that reconstruction approaches which integrate or make use of the FVR registration method may have an advantage in performing 3D reconstructions in these types of scenes, scenes which are of common disturbance to many existing feature matching methods, as expressed in the literature.   

