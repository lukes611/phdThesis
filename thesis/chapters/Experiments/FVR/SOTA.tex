\subsection{Pose Estimation Results}

In these experiments, several current techniques (2D Feature Matching (FM-2D), 3D Feature Matching (FM-3D), ICP and PCA) are compared to the FVR technique in terms of registration accuracy. Comparisons are made over the 3D video frame data described in section \ref{TestDataSection}. As discussed, these 3D video frame scenes contain both different types of environments and are captured using different camera movement techniques. Different camera movements tested include: translational movement, rotational movement and camera zoom. These scenes consist of environments which include: both in-door and out-door environments, low-textured areas and areas which include texture confusion. \\

Experiment results are graphed and presented in this section with the x-axis indicating frame number, whilst the y-axis indicated registration error with respect to the un-registered 3D frames. For example, the $n^{th}$ column along the x-axis represents the error in registering the $n^{th}$ frame with the $(n+1)^{th}$ frame with respect to no registration performed. The y-axis error represents the amount of error (or non-overlap) of the registration between the current and consecutive frames. This error was described in the metrics section (section \ref{metricsSection}). The error function used is the Mean Squared Error $MSE(P,Q)$. This error is computed between the consecutive frames before and after registration. The error post registration is used but is scaled by the prior error, this way all errors are normalized relative to the same value. This error value is computed as in equation \ref{eqn:msesota}. Here, the function $Register(x)$ is replaced by the registration method being tested. \\

\begin{equation} \label{eqn:msesota}
Error(frame_1, frame_2) =  \frac{Register(frame_1), frame2}{MSE(frame_1,frame_2)}
\end{equation}


Each experiment's data is also tabled for convenience. For each algorithm, the average registration error is given. This is computed by summing up the error values for a particular algorithm and dividing by the total number of frames in the experiment. Assisting this is the percent of best results metric. This measures in percentage, the amount of times a particular algorithm achieved the best (lowest error) registration result compared to the other algorithms tested. An algorithm with a lower average error compared to another algorithm would be said to have performed better overall. Additionally, if an algorithm has a higher percentage of best results, it outperformed the other algorithms a majority of the time. If an algorithm achieved the a higher percentage of bests results but a higher average error, this could be explained by outliers. If an algorithm achieved a lower average error but did not achieve the highest percentage of best results, it may be due to having a very competitive and consistent registration error. \\

These experiments were performed by capturing the environment using the ASUS XTION PRO LIVE active depth camera. The frames were captured and stored to a computer hard-drive prior to being processed using each algorithm. \\

%pet0 : apartment texture rotate
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Apartment_Texture_Rotate}
\caption{Registration Error for the Apartment Y-Axis Rotation Data Set}
\label{fig:PET0}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best results}\\ \hline
FM-2D	& 27.52 & ~17.39\\
FM-3D	& 49.80 & 0\\
ICP		& 27.39 & ~17.39\\
PCA		& 37.82 & 0\\
FVR		& 26.87 & ~65.217\\
\end{tabular}
\captionof{table}{Statistics for the Apartment Y-Axis Rotation Data Set}
%\label{tab:PET0ST}
\end{figure} 



In figure \ref{fig:PET0}, feature-matching, 3D-feature-matching, ICP, PCA and Fourier Volume Registration (FVR) were tested. Overall, the 2D feature matching has the lowest average error out of the two feature matching methods. This scene is of the inside of an apartment which contains various pieces of furniture and plenty of textural information. The camera was rotated about the y-axis whilst moving the camera (translation) across the room. ICP performed slightly better than FM-2D but the FVR algorithm was shown to have the lowest average error. Additionally to being consistent, the FVR method had the largest percentage of best results. At a value of ~65\%, this means that for around 65\% of the frames, the FVR method gave the optimal result compared to the others. Here ICP and FM-2D performed similarly. Both PCA and FM-3D performed worse-off. In this type of scene where much texture information is plentiful, this is ideal for feature matching methods. Additionally, frames were not highly separated so it is ideal for ICP also. ICP is shown to be consistent yet does not reach the performance of the FVR algorithm. \\


%pet 1 apartment texture rotate x-axis
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Apartment_Texture_Rotate_XAxis}
\caption{Registration Error for the Apartment X/Y-Axis Rotation Data Set}
\label{fig:PET1}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 624.3 & ~13.04\\
FM-3D	& 841.3 & 0\\
ICP		& 584.2 & ~43.48\\
PCA		& 1005.1 & 0\\
FVR		& 576.86 & ~43.48\\
\end{tabular}
\captionof{table}{Statistics for the Apartment X/Y-Axis Rotation Data Set}
%\label{tab:PET1ST}
\end{figure} 



Figure \ref{fig:PET1} shows registration errors for the the apartment scene again, this time the camera is moved about the x-axis predominantly, again this scene contains lots of texture. In a about 43\% of the frames, FVR either outperforms the other algorithms. Here, ICP performs next best with the same statistic for the percentage of best result metric. 2D-feature matching is also very competitive with 3D-feature-matching and PCA failing to register most frames as accurately as the others. In the case of PCA, when there is not enough overlapping data to register, inaccurate registrations occur. When the FVR technique uses PCA, it only uses the primary axis, and refines the alignment in the secondary stage. Additionally, according to the average error metric, the FVR is shown to be the best performer with the lowest average error. \\


%pet 2 Boxes Y-Axis Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Boxes_Texture_Rotate}
\caption{Registration Error for the Boxes Y-Axis Rotation Data Set}
\label{fig:PET2}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 574.48 & ~33.3\\
FM-3D	& 19502.3 & ~3.7\\
ICP		& 550.3 & ~33.3\\
PCA		& 981.6 & 0\\
FVR		& 508.13 & ~29.6\\
\end{tabular}
\captionof{table}{Statistics for the Boxes Y-Axis Rotation Data Set}
%\label{tab:PET2ST}
\end{figure} 





In figure \ref{fig:PET2} 7 frame registration errors are shown for the Boxes scene. This scene contains camera rotation about the y-axis where in different views were observed during frame capture. In around 30\% of the frames, FVR outperformed the other algorithms. Here both IPC and FM-2D performed similarly. Despite not achieving the largest number of optimal results, the FVR has the lowest average error, meaning it consistently outperformed others or at least matched their performance closely.  \\



%pet 3 Boxes Zoom Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Boxes_Texture_ZoomOut}
\caption{Registration Error for the Boxes Zoom Data Set}
\label{fig:PET3}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 0.68 & ~18.18\\
FM-3D	& 0.73 & 0\\
ICP		& 0.59 & ~27.27\\
PCA		& 0.73 & 0\\
FVR		& 0.65 & ~54.54\\
\end{tabular}
\captionof{table}{Statistics for the Boxes Zoom Data Set}
%\label{tab:PET3ST}
\end{figure} 

%pet 4 Boxes Zoom Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Desk_Texture_Translation}
\caption{Registration Error for the Desk Translation Data Set}
\label{fig:PET4}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 874.18 & ~8.7\\
FM-3D	& 1447.42 & ~4.35\\
ICP		& 818.41 & ~26.09\\
PCA		& 1011.59 & ~8.7\\
FVR		& 740.33 & ~52.17\\
\end{tabular}
\captionof{table}{Statistics for the Desk Translation Data Set}
%\label{tab:PET4ST}
\end{figure} 


Experiment results for another boxes scene are shown in figure \ref{fig:PET3}. In this scene, the camera was moved forward and backward, effectively changing focus on different parts of the same set of boxes at different times during frame capture. Here the FVR algorithm achieved the optimal result in around 55\% of the frames. ICP performed next best with a percentage of best results of around 27\%. Additionally the FVR method also achieved a lower average error compared to the other algorithms. \\


In ~52\% of the frames of the desk translation data-set in figure \ref{fig:PET4}, the FVR method outperformed others relative to just ~26\% for ICP, ~9\% for 2D-feature-matching and PCA and ~4\% for 3D-feature-matching. This data-set tests each procedure's ability to reconstruct a scene captured by moving a camera forward along a path. 3D feature matching was a notable poor performer here. Additionally FVR outperformed the other methods overall in terms of having the lowest average error. \\

%pet 5 Texture Confusion Indoor-Space Translation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/IndoorSpace_texture_confusion_translation}
\caption{Registration Error for the Texture Confusion Indoor-Space Translation Data Set}
\label{fig:PET5}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 715.72 & ~22.22\\
FM-3D	& 992.34 & 0\\
ICP		& 687.31 & ~33.33\\
PCA		& 975.77 & 0\\
FVR		& 630.47 & ~44.44\\
\end{tabular}
\captionof{table}{Statistics for the Texture Confusion Indoor-Space Translation Data Set}
%\label{tab:PET5ST}
\end{figure} 


An important data-set tested is the Indoor-Space with texture confusion (figure \ref{fig:PET5}). Here, a small scene was observed, where texture-confusion was present, this makes registration more difficult for all algorithms most notably the feature matching methods. We suspected that ICP, PCA, and FVR would perform best with this data set. \\

Here, around 44\% of the time, FVR performed best. Additionally it had the lowest average error compared to all the other algorithms. The 2D-FM method achieved the best registration result around 22\% of time, and ICP improved on this at around 33\% of the time. It is clear that 2D-FM and ICP also work quite well but they do not reach the performance of the FVR method. \\ 


%pet 6 Texture Confusion Indoor-Space Translation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Kitchen_LittleTexture_Pan}
\caption{Registration Error for the Low-Texture Kitchen Translation Data Set}
\label{fig:PET6}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 3450.6 & ~11.11\\
FM-3D	& 973.27 & 0\\
ICP		& 772.9 & ~27.77\\
PCA		& 1029 & ~16.66\\
FVR		& 638.5 & ~44.44\\
\end{tabular}
\captionof{table}{Statistics for the Low-Texture Kitchen Translation Data Set}
%\label{tab:PET6ST}
\end{figure} 


Results for the low-textured Kitchen data-set were collected and shown in figure \ref{fig:PET6}. Again around 44\% of the frames had best results given by FVR. Compared with the next best algorithm ICP at ~27\%. In this case, this is expected as the feature-matching methods should perform worse in a low-textured scene. PCA was next best having the best registration ~22\% of the time. \\


%pet 7 Low-Texture Kitchen Zoom Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Kitchen_Little_Texture_Zoom}
\caption{Registration Error for the Low-Texture Kitchen Zoom Data Set}
\label{fig:PET7}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 1645.35 & ~7.69\\
FM-3D	& 899.43 & ~7.69\\
ICP		& 833.2 & ~46.15\\
PCA		& 1062.88 & ~15.38\\
FVR		& 875.85 & ~23.08\\
\end{tabular}
\captionof{table}{Statistics for the Low-Texture Kitchen Zoom Data Set}
%\label{tab:PET7ST}
\end{figure} 



Another test for the low-textured Kitchen scene was also performed, this time by moving the camera forward and backwards, zooming in on the scene. In this test, FVR only outperformed the other methods in around 23\% of the frames. ICP outperformed FVR and the other algorithms in around 46\%. Here, FVR performed second best, with an average error performance close to that of ICP. This result is different from the previous result with the low-textured Kitchen scene. There (figure \ref{fig:PET6}), FVR outperformed all of the other methods. This scene is different in that the camera was translated back and forth rather than side to side. Still, the FVR performed competitively compared to the other algorithms.  \\


%pet 8 Office Translation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Office_TexturedItems_Translation}
\caption{Registration Error for the Office Translation Data Set}
\label{fig:PET8}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 712.97 & 20\\
FM-3D	& 367040 & 0\\
ICP		& 710.34 & ~33.33\\
PCA		& 1001.43 & ~6.67\\
FVR		& 674.78 & 40\\
\end{tabular}
\captionof{table}{Statistics for the Office Translation Data Set}
%\label{tab:PET8ST}
\end{figure} 


In the results for the Textured Office set (figure \ref{fig:PET8}), FVR matched or beat the other algorithms around 40\% of the time. 2D-feature matching also performed well but did not manage to best FVR most of the time. This result shows that FVR not only works well compared to other algorithms in scenes with little or no texture or in scenes where feature confusion is high, but also in high texture scenes where feature-matching and ICP should have an advantage. The FVR algorithm also had the lowest average registration error compared to these other iterative methods. \\

%pet 9 Office Centered Object Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Office_Texture_blind_spot_rotation}
\caption{Registration Error for the Office Centered Object Rotation Data Set}
\label{fig:PET9}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 666.04 & 10\\
FM-3D	& 391310.1 & 0\\
ICP		& 577.93 & 60\\
PCA		& 1026.54 & 0\\
FVR		& 583.42 & 30\\
\end{tabular}
\captionof{table}{Statistics for the Office Centered Object Rotation Data Set}
%\label{tab:PET9ST}
\end{figure} 


Figure \ref{fig:PET9} shows results for the centred object rotation scene. Here, a large divider was placed in the middle of two desks. The idea was to create an environment where the large divider could throw off the effects of PCA and FVR and give an advantage to the feature matching approaches and ICP. Interestingly, around 30\% of the time, FVR had the best result. 2D-feature-matching outperformed the 3D counterpart but only got achieved the best registration performance around 10\% of the time. ICP on the other hand got the best result for around 60\% of the frames. In this scene ICP is able to use the large divider as an anchor which would make it more robust to non-overlapped data.

%pet 10 Office X/Y-Axis Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Office_Texture_Rotate_XAxis}
\caption{Registration Error for the Office X/Y-Axis Rotation Data Set}
\label{fig:PET10}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 686.48 & ~56.25\\
FM-3D	& 2080.65 & ~6.25\\
ICP		& 705.76 & ~18.75\\
PCA		& 964.13 & 0\\
FVR		& 697.27 & ~18.75\\
\end{tabular}
\captionof{table}{Statistics for the Office X/Y-Axis Rotation Data Set}
%\label{tab:PET10ST}
\end{figure} 


Another experiment where the scene was filmed with the camera rotated predominantly about the x-axis is shown in figure \ref{fig:PET10}, this time 2D-feature-matching outperformed the others. FVR and ICP performed second best in terms of the percent of best results achieved but FVR had a lower average registration error which came close to beating FM-2D.  

%pet 11 Office Y-Axis Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Office_Texture_Rotation}
\caption{Registration Error for the Office Y-Axis Rotation Data Set}
\label{fig:PET11}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 530 & ~35.71\\
FM-3D	& 934.53 & 0\\
ICP		& 528.47 & ~28.57\\
PCA		& 1000.78 & 0\\
FVR		& 533.23 & ~35.71\\
\end{tabular}
\captionof{table}{Statistics for the Office Y-Axis Rotation Data Set}
%\label{tab:PET11ST}
\end{figure} 


Figure \ref{fig:PET11} shows the registration errors for the Office data-set with camera rotation about the Y-axis. Here, in around 50\% of the cases, FVR outperformed or matched the best result. 2D-feature-matching was next best matching or outperforming the best result around 34\% of the time. Interestingly, PCA performed the worst with this data-set. Because rotation can incur a smaller overlap and thus a large shift in the axes and mean of the principal components, this could be expected. \\

%pet 12 Office Translation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Office_Texture_Translation}
\caption{Registration Error for the Office Translation Data Set}
\label{fig:PET12}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 773.23 & ~6.67\\
FM-3D	& 2696.51 & 0\\
ICP		& 636.84 & 40\\
PCA		& 999.57 & 0\\
FVR		& 621.72 & ~53.33\\
\end{tabular}
\captionof{table}{Statistics for the Office Translation Data Set}
\label{tab:PET12ST}
\end{figure} 


In the Office translation scene, FVR outperformed or matched the other algorithms around 85\% of the time. This shows that the FVR has high accuracy when dealing with translation detection and the registration of 3D data with only translational changes. Here, PCA and 3D-feature matching performed the worst with ICP and 2D-feature matching being consistent and robust also. \\

%pet 13 Little Texture Outdoors Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Outside_No_Texture_Rotation}
\caption{Registration Error for the Little Texture Outdoors Rotation Data Set}
\label{fig:PET13}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 497.83 & ~11.11\\
FM-3D	& 12411.23 & ~5.56\\
ICP		& 414.87 & ~27.78\\
PCA		& 1008.22 & 0\\
FVR		& 327.95 & ~55.56\\
\end{tabular}
\captionof{table}{Statistics for the Little Texture Outdoors Rotation Data Set}
\label{tab:PET13ST}
\end{figure} 


Figure \ref{fig:PET13} shows results for an outdoors scene with little texture, here the camera was rotated about an origin. In this case, PCA performed the worst, and 3D-feature-matching also failed several times. The only algorithm which did not fail once was FVR. In this test, FVR outperformed or matched the other algorithms 88\% of the time. This can be explained by FVR's robustness to out-door scenes and scenes with little texture.  \\

%pet 14 Little Texture Outdoors Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Outside_No_Texture_Translation}
\caption{Registration Error for the Little Texture Outdoors Translation Data Set}
\label{fig:PET14}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 716.1 & ~4.35\\
FM-3D	& 678.65 & 0\\
ICP		& 402.16 & ~39.13\\
PCA		& 980.15 & 0\\
FVR		& 379.06 & ~56.52\\
\end{tabular}
\captionof{table}{Statistics for the Little Texture Outdoors Translation Data Set}
\label{tab:PET14ST}
\end{figure} 

Another test using a low-textured out-doors scene was tested where the camera was translated along a path. Results are shown in figure \ref{fig:PET14}. Here again the FVR method dominated recording either the best result or matching best result for around 73\% of the frames. Notably, PCA performed poorly, and both the feature-matching methods failed to register a few times. ICP was more consistent, recoding the best or equivalent result around 47\% of the time. Again, this shows the strength of the FVR method in out-door and low-texture environments. 


%pet 15 Little Texture Outdoors Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Outside_TextureConfusion_Rotation}
\caption{Registration Error for the Outdoors Texture Confusion Rotation Data Set}
\label{fig:PET15}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 1274.19 & 12.5\\
FM-3D	& 2336.98 & 0\\
ICP		& 452.08 & 25\\
PCA		& 951.42 & 0\\
FVR		& 450.07 & 62.5\\
\end{tabular}
\captionof{table}{Statistics for the Outdoors Texture Confusion Rotation Data Set}
\label{tab:PET15ST}
\end{figure}


Another test was performed with an outdoors scene. Here only 8 of the frames had any good results for all algorithms. They are shown in figure \ref{fig:PET15}. In these results, 6 out of the 8 frames had either a matching or best registration for the FVR method. 2D-feature-matching and 3D-feature-matching both failed a few times, and PCA was inconsistent. ICP had a competitive result 3 out of the 8 times, both FVR and ICP were most consistent. 


%pet 16 Outdoors Texture Confusion Translation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Outside_TextureConfusion_Translation}
\caption{Registration Error for the Outdoors Texture Confusion Translation Data Set}
\label{fig:PET16}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 765.94 & ~27.78\\
FM-3D	& 375694.14 & 0\\
ICP		& 676.02 & ~33.33\\
PCA		& 1023.48 & 0\\
FVR		& 676.51 & ~38.89\\
\end{tabular}
\captionof{table}{Statistics for the Outdoors Texture Confusion Translation Data Set}
\label{tab:PET16ST}
\end{figure}

Another scene with texture-confusion was taken out-doors. The interesting results are shown in figure \ref{fig:PET16}. Here, 3D-feature matching failed a majority of the time. Interestingly PCA also failed, the likely reason is because of the amount of noise in an out-doors scene. This noise can give inconsistencies in the principal axes and mean computation. Again, FVR performed best with it getting the best or equivalent result around 55\% of the time. This is another experiment where FVR is shown to be highly robust to scenes with texture confusion. 

%pet 17 Outdoor Plants Texture Confusion Rotation Data Set
\begin{figure}
\centering
\includegraphics[width=6in]{images/results/Plants_Outdoors_Texture_Confusion_Rotation}
\caption{Registration Error for the Outdoor Plants Texture Confusion Rotation Data Set}
\label{fig:PET17}

\begin{tabular}{ccc}
\hline
\textbf{Algorithm} & \textbf{Average Error $\times$ 1000} & \textbf{\% best result}\\ \hline
FM-2D	& 518.02 & ~23.81\\
FM-3D	& 12791.22 & 0\\
ICP		& 742.37 & ~4.76\\
PCA		& 984.14 & 0\\
FVR		& 450.06 & ~66.67\\
\end{tabular}
\captionof{table}{Statistics for the Outdoor Plants Texture Confusion Rotation Data Set}
\label{tab:PET17ST}
\end{figure}


The final figure in the pose estimation tests shows another scene taken out-doors. This scene also contains texture confusion, but the camera was rotated about an axis rather than translated in this data-set. Results shown in figure \ref{fig:PET17} indicate that again FVR dominates with 16 out of the 21 frames having a matching or best registration by FVR. 
